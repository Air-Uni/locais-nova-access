```{r}
#| label: setup
#| include: false

library(here)

source(here("R", "_setup.R"))
```

<!-- badges: start -->
[![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
[![License: GPLv3](https://img.shields.io/badge/license-GPLv3-bd0000.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC_BY--NC--SA_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
<!-- badges: end -->

::: {.callout-important}
This pipeline is a **Work In Progress** (WIP) and is under active development. It may not yet be stable or suitable for public use. Please use it with caution and report any issues you encounter.
:::

## Overview

This report presents a reproducible pipeline for generating [hexagonal grids](https://en.wikipedia.org/wiki/Grid_(spatial_index)) of Brazilian municipalities. The pipeline was developed in the [R programming language](https://www.r-project.org/) by **Flávio Soares** and **Clara Penz**, with further adaptations by [**Daniel Vartanian**](https://github.com/danielvartan).

For instructions on how to run the pipeline, see the repository [README](https://github.com/cem-usp/brazil-hexagonal-grid/blob/main/README.md).

## Problem

## Data Availability

::: {style="text-align: left;"}
[![](https://img.shields.io/badge/OSF%20ID-00000-1284C5.svg)](https://osf.io)
:::

The processed data are available in both [`rds`](https://rdrr.io/r/base/readRDS.html) and [`parquet`](https://en.wikipedia.org/wiki/Apache_Parquet) formats through a dedicated repository on the Open Science Framework ([OSF](https://osf.io/)). A metadata file is included alongside the validated datasets.

Because the raw data are not publicly available, only authorized personnel can access the processed files. They are protected with [RSA](https://en.wikipedia.org/wiki/RSA_cryptosystem) 4096-bit encryption ([OpenSSL](https://www.openssl.org/)) and a 32-byte password to ensure data security.

If you already have access to the OSF repository and the project keys, click [here](https://osf.io/) to access the data. A backup copy of the raw data is also stored on OSF and can be accessed [here](https://osf.io/zuy4s/). You can also retrieve these files directly from [R](https://www.r-project.org/) using the [`osfr`](https://docs.ropensci.org/osfr/) package.

## Methods

### Source of Data

The data used in this report come from the following sources:

- Brazilian Institute of Geography and Statistics ([IBGE](https://www.ibge.gov.br/)): Data from the [2022 Brazilian Census](https://en.wikipedia.org/wiki/2022_Brazilian_census).
- [Mapzen Terrain Tile](https://registry.opendata.aws/terrain-tiles/): Data on terrain and elevation.
- OpenStreetMap ([OSM](https://www.openstreetmap.org/)): Geospatial data on highways, roads, and other infrastructure for Brazilian municipalities.
- [OpenTopography](https://opentopography.org/): Data on topography and elevation.

### Data Munging

The data munging follow the data science workflow outlined by @wickham2023e, as illustrated in [@fig-wickham-at-al-2023-figure-1]. All processes were made using the [Quarto](https://quarto.org/) publishing system [@allaire], the [R programming language](https://www.r-project.org/) [@rcoreteama] and several R packages.

For data manipulation and workflow, priority was given to packages from the [tidyverse](https://www.tidyverse.org/), [rOpenSci](https://ropensci.org/) and [r-spatial](https://r-spatial.org/) ecosystems, as well as other packages adhering to the tidy tools manifesto [@wickham2023c].

::: {#fig-wickham-at-al-2023-figure-1}
![](images/wickham-at-al-2023-figure-1.png){width=75%}

[Source: Reproduced from @wickham2023e.]{.legend}

Data science workflow created by Wickham, Çetinkaya-Runde, and Grolemund.
:::

### Code Style

The Tidyverse [code style guide](https://style.tidyverse.org/) and [design principles](https://design.tidyverse.org/) were followed to ensure consistency and enhance readability.

### Reproducibility

The pipeline is fully reproducible and can be run again at any time. To ensure consistent results, the [`renv`](https://rstudio.github.io/renv/) package [@usheya] is used to manage and restore the R environment. See the [README](https://github.com/cem-usp/brazil-hexagonal-grid/blob/main/README.md) file in the code repository to learn how to run it.

## Set the Environment

### Load Packages

```{r}
#| label: Set the Environment
#| output: false

library(arrow)
library(beepr)
library(curl)
library(dplyr)
library(elevatr)
library(fs)
library(geobr)
library(h3jsr)
library(here)
library(htmltools)
library(lockr) # github.com/danielvartan/lockr
library(magrittr)
library(osfr)
library(osmdata)
library(raster)
library(readr)
library(sf)
library(sfarrow)
library(tictoc)
```

### Set Keys

```{r}
osf_pat <- Sys.getenv("OSF_PAT") # askpass()
```

```{r}
#| eval: false
#| output: false

osf_auth(osf_pat)
```

```{r}
public_key <- here("_ssh", "id_rsa.pub")
```

```{r}
private_key <- here("_ssh", "id_rsa")
```

```{r}
password <- Sys.getenv("ACESSOSAN_PASSWORD") # askpass()
```

### Set Input and Output Paths

```{r}
dir_inputs <- here("1-inputs")
dir_parcial <- here("2-parcial")
```

```{r}
for (i in c(dir_inputs, dir_parcial)) {
  if (!dir_exists(i)) {
    dir_create(i, recurse = TRUE)
  }
}
```

### Set Municipality Data

```{r}
municipios <- c(
  3550308, # São Paulo
  2507507, # João Pessoa
  3106200, # Belo Horizonte
  4314902, # Porto Alegre
  1721000, # Palmas
  5300108, # Brasília
  5208707  # Goiânia
)
```

### Set Initial Variables

```{r}
set.seed(2025)
```

## Download IBGE Census Data

### Download File

```{r}
#| eval: false
#| label: Download IBGE Census Data

osf_raw_data_id <- "zuy4s"
```

```{r}
#| eval: false

osf_raw_data_files <-
  osf_raw_data_id |>
  osf_retrieve_node() |>
  osf_ls_files(
    type = "file",
    pattern = "censo2022_hex",
    n_max = Inf
  )

osf_raw_data_files
```

```{r}
#| eval: false

ibge_2022_census_hex_file <-
  osf_raw_data_files |>
  osf_download(path = dir_inputs, conflicts = "overwrite") |>
  extract2("local_path")
```

### Unlock File

```{r}
#| eval: false
#| output: false

ibge_2022_census_hex_file <-
  ibge_2022_census_hex_file |>
  unlock_file(
    private_key = private_key,
    suffix = ".lockr",
    remove_file = TRUE,
    password = password
  )
```

```{r}
#| echo: false

ibge_2022_census_hex_file <- here(dir_inputs, "censo2022_hex.csv")
```

## Download Brazil OSM Data

```{r}
#| label: Download Brazil OSM Data
#| eval: false

file.path(
  "https://download.geofabrik.de",
  "south-america",
  "brazil-latest.osm.pbf"
) |>
  curl_download(
    destfile = here(dir_inputs, "brazil-latest.osm.pbf"),
    quiet = FALSE
  )
```

```{r}
osm_brazil_latest_file <- here(dir_inputs, "brazil-latest.osm.pbf")
```

## 01.01-criar_malha_hexagonal_areas_total_urbana.R

> Cria malhas hexagonais para os municípios a serem analisados.
>
> Aqui teria 2 etapas que estão faltando no script:
>
> 1. Trabalhar a área urbanizada do IBGE.
> 2. Gerar hexágonos da área urbanizada.

### Ler Hexágonos Urbanizados do Brasil com Dados do Censo 2022

```{r}
#| label: 01.01-criar_malha_hexagonal_areas_total_urbana.R
#| eval: false

hexurb <-
  ibge_2022_census_hex_file |>
  read_delim(delim = ",") |>
  # Filtrar fora linhas com somente 0 em todas as variáveis exceto `h3_address`.
  filter(!if_all(-h3_address, \(x) x == 0))

hexurb |> glimpse()
```

### Criar Malha Hexagonal e Separar entre Urbano e Não-Urbano

```{r}
#| eval: false

for (cod in municipios) {
  # Baixar geometria do município.
  municipio_geom <- read_municipality(code_muni = cod, year = 2020)

  # Converter polígono para células H3.
  hex <- polygon_to_cells(geometry = municipio_geom$geom, res = 9)

  # Converter células H3 de volta para polígonos.
  hexgrid <- cell_to_polygon(input = hex, simple = FALSE)

  print(paste("Malha hexagonal criada para", cod))

  # Separar hexágonos urbanizados.
  hex_urb_mun <-
    hexgrid |>
    left_join(hexurb, by = "h3_address") |>
    filter(if_all(-h3_address, ~ !is.na(.x))) |>
    mutate(across(where(is.numeric) & !any_of("h3_address"), abs))

  print("Filtragem realizada")

  # Criar diretório.
  dir_hex <- file.path(dir_parcial, cod, "hex")
  dir.create(dir_hex, showWarnings = FALSE, recursive = TRUE)

  # Salvar arquivos.
  # Total
  st_write_parquet(hexgrid, file.path(dir_hex, "hex.parquet"))
  # Urbanizado
  st_write_parquet(hex_urb_mun, file.path(dir_hex, "hex_urbanizado.parquet"))
}
```

## 01.02-processar_elevation.R

### Criar Arquivo `.tiff` para a Área Urbanizada de Cada Município

```{r}
#| label: 01.02-processar_elevation.R
#| eval: false

for (cod in municipios) {
  # Definir caminho do arquivo `.tiff`.
  elevation_path <- file.path(dir_parcial, cod, "elevation.tiff")

  # Ler `hexgrid` do município
  hexgrid <-
    file.path(
      dir_parcial,
      cod,
      "hex",
      "hex_urbanizado.parquet"
    ) |>
    st_read_parquet()

  # Criar raster de elevação (zoom `z=13`)
  elev_raster <-
    hexgrid |>
    get_elev_raster(
      z = 13,
      override_size_check = TRUE
    )

  # Salvar .tiff
  writeRaster(elev_raster, elevation_path, overwrite = TRUE)

  print(paste("Arquivo .tiff criado para município", cod))
}
```

## 01.03-processar_osm.R

### Criar Malha de Transporte para a Área Urbanizada de Cada Município

```{r}
#| label: 01.03-processar_osm.R
#| eval: false
#| output: false

for (cod in municipios) {
  print(paste("Processando", cod))

  # Definir diretório de saída.
  dir_mun <- file.path(dir_parcial, cod)
  dir.create(dir_mun, showWarnings = FALSE, recursive = TRUE)

  # Bounding box do município.
  mun_hex <-
    file.path(
      dir_mun,
      "hex",
      "hex_urbanizado.parquet"
    ) |>
    st_read_parquet()

  mun_bbox <- st_bbox(mun_hex)
  br_pbf <- osm_brazil_latest_file
  mun_pbf <- file.path(dir_mun, "redeviaria.osm.pbf")

  # Executa Osmosis.
  tic(msg = paste("Extraindo malha OSM para", cod))
  system2(
    "osmosis",
    args = c(
      paste("--read-pbf", br_pbf),
      "--bounding-box",
      paste0("left=", mun_bbox["xmin"]),
      paste0("bottom=", mun_bbox["ymin"]),
      paste0("right=", mun_bbox["xmax"]),
      paste0("top=", mun_bbox["ymax"]),
      paste("--write-pbf", mun_pbf)
    )
  )
  toc()
}
```

```{r}
#| eval: false
#| echo: false

# DO NOT RUN!

# This code block illustrates the use of the `osmdata` package to extract
# OSM data. You don´t need to run it, since the previous code already does this.

for (cod in municipios) {
  print(paste("Processando", cod))

  # Definir diretório de saída.
  dir_mun <- file.path(dir_parcial, cod)
  dir.create(dir_mun, showWarnings = FALSE, recursive = TRUE)

  # Bounding box do município.
  mun_hex <-
    file.path(
      dir_mun,
      "hex",
      "hex_urbanizado.parquet"
    ) |>
    st_read_parquet()

  mun_bbox <- st_bbox(mun_hex)
  mun_osm_file <- file.path(dir_mun, "redeviaria.parquet")

  tic(msg = paste("Extraindo malha OSM para", cod))
  osm_query <-
    mun_bbox |>
    opq() |>
    add_osm_feature(key = "highway")

  osm_result <- osmdata_sf(osm_query)
  toc()

  osm_result |>
    extract2("osm_lines") |>
    st_write_parquet(mun_osm_file)
}
```

```{r}
#| echo: false

# beep(3)
```

## 02.04-rais_calcular_matriz_tempo_viagem.R

Incluir dados com baixa precisão?

```{r}
#| eval: false

# ------------------------- #
# Calcular matriz de tempo
# de viagem para municipios
# ------------------------- #

# Necessarias etapas de instalacao do ambiente:
# 1. Instalar o Java Development Kit (JDK)
#    - Baixar do site oficial: https://www.oracle.com/java/technologies/javase-downloads.html
#    - Escolher a versao adequada (por exemplo, JDK 17)
#    - Seguir instalacao padrao do sistema operacional
#    - Configurar a variavel de ambiente JAVA_HOME apontando para a pasta de instalacao do JDK
#    - Adicionar JAVA_HOME/bin ao PATH do sistema

# 2. Instalar o Osmosis (para processamento de OSM)
#    - Baixar do site oficial: https://wiki.openstreetmap.org/wiki/Osmosis
#    - Descompactar em uma pasta local
#    - Adicionar o diretorio bin do Osmosis ao PATH do sistema (opcional)
#    - Testar executando 'osmosis --help' no terminal para verificar se funciona


# Bibliotecas ----
library(arrow) # arquivos .parquet
library(sf) # oreacoes de geometria
library(tictoc) # tempo de processamento
library(r5r) # Calculo de tempos de viagem entre pontos

# Definir diretorio de trabalho -----------------------------------------
setwd("D:/CEM_acessoSAN_ac/")

dir_inputs <- "1-inputs" # Deixar arquivos de input aqui
dir_parcial <- "2-parcial" # Arquivos com algum processamento


# Listar municipios -----------------------------------------------------
municipios <- c(
  3550308,   # Sao Paulo
  2507507,   # Joao Pessoa
  3106200,   # Belo Horizonte
  4314902,   # Porto Alegre
  1721000,   # Palmas
  5300108,   # Brasilia
  5208707    # Goiania
)

# Calcular matriz de tempo de viagem -----------------------------------

# Configurações do R5R -------------------------------------------------
options(java.parameters = c("-Xmx2G", "-XX:ActiveProcessorCount=4"))
Sys.setenv(JAVA_HOME = "C:/Program Files/Java/jdk-21")

hex <- 9
mode <- c("WALK")
max_walk_dist <- 3000
max_trip_duration <- 60
departure_datetime <- as.POSIXct("13-05-2019 14:00:00",
                                 format = "%d-%m-%Y %H:%M:%S")

tipos <- c("pantano", "deserto")

for (mun in municipios) {

  message("Processando municipio: ", mun)

  # Caminhos ------------------------------------------------------------
  dir_mun <- file.path(dir_parcial, mun)

  osmosis_path <- file.path(dir_inputs, "OSM/osmosis-0.49.2/bin/osmosis.bat")
  br_pbf <- file.path(dir_inputs, "OSM/brazil-latest-filtered.osm.pbf")
  mun_pbf <- file.path(dir_mun, "redeviaria.osm.pbf")

  caminho_hex_urbanizado <- file.path(dir_mun, "hex/hex_urbanizado.parquet")

  # Extrair bounding box dos hexagonos ---------------------------------
  mun_hex <- sfarrow::st_read_parquet(caminho_hex_urbanizado)
  mun_bbox <- st_bbox(mun_hex)

  # Comando Osmosis -----------------------------------------------------
  osmosis_cmd <- sprintf(
    "%s --read-pbf %s --bounding-box left=%s bottom=%s right=%s top=%s --write-pbf %s",
    osmosis_path, br_pbf,
    mun_bbox["xmin"], mun_bbox["ymin"],
    mun_bbox["xmax"], mun_bbox["ymax"],
    mun_pbf
  )

  # Executar Osmosis ----------------------------------------------------
  tictoc::tic(msg = paste("Extraindo malha OSM para", mun))
  shell(osmosis_cmd, translate = TRUE)
  tictoc::toc()

  # Inicializar R5 ------------------------------------------------------
  caminho_core <- file.path(dir_parcial, mun)
  r5r_core <- r5r::setup_r5(data_path = caminho_core, verbose = FALSE)

  # Preparar centroides dos hexagonos ----------------------------------
  centroides <- mun_hex %>%
    st_centroid() %>%
    mutate(
      id = h3_address,
      lat = st_coordinates(.)[, 2],
      lon = st_coordinates(.)[, 1]
    ) %>%
    st_drop_geometry() %>%
    arrange(id)

  # Loop sobre tipos ----------------------------------------------------
  for (tipo in tipos) {
    message("Tipo: ", tipo)

    caminho_rais <- file.path(dir_mun, "rais", paste0("rais_", tipo, "_geocod.parquet"))
    if (!file.exists(caminho_rais)) {
      message("[Aviso] Arquivo não encontrado: ", caminho_rais)
      next
    }

    # Preparar RAIS geocodificado
    rais <- read_parquet(caminho_rais)

    # Contar NAs antes de remover
    n_na <- sum(is.na(rais$lat) | is.na(rais$lon))
    message("Removendo ", n_na, " registros sem coordenadas (lat/lon NA)")

    # Dropar NAs e ordenar
    rais <- rais %>%
      tidyr::drop_na(lat, lon)


    rais <- rais %>%
      st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
      st_transform(st_crs(mun_hex)) %>%
      mutate(
        id = cnpj,
        lat = st_coordinates(.)[, 2],
        lon = st_coordinates(.)[, 1]
      ) %>%
      st_drop_geometry() %>%
      arrange(id)

    # Calcular matriz de tempo ------------------------------------------
    ttm <- r5r::travel_time_matrix(
      r5r_core = r5r_core,
      origins = centroides,
      destinations = rais,
      mode = mode,
      departure_datetime = departure_datetime,
      max_trip_duration = max_trip_duration,
      verbose = FALSE
    )

    # Salvar resultado --------------------------------------------------
    out_dir <- file.path(dir_mun, "rais", "tempos")
    dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

    caminho_saida <- file.path(out_dir, paste0("ttm_", tipo, ".rds"))
    saveRDS(ttm, file = caminho_saida)
    message("Arquivo salvo: ", caminho_saida)
  }

  # Limpar memória ------------------------------------------------------
  rm(r5r_core)
  gc()

  message("Municipio ", mun, " concluido.")
}
}
```

## 02.05-rais_calcular_acesso.R

```{r}
#| eval: false

# --------------------------------- #
# Produzir geometrias hexagonais para
# pontos de acesso a estabelecimentos
# --------------------------------- #

# Bibliotecas ----
library(arrow)     # leitura de arquivos .parquet
library(sf)        # operações de geometria
library(dplyr)     # manipulação de dados
library(sfarrow)   # leitura de parquet com geometria

# Definir diretorio de trabalho -----------------------------------------
setwd("D:/CEM_acessoSAN_ac/")

dir_inputs <- "1-inputs" # arquivos de input
dir_parcial <- "2-parcial" # arquivos intermediarios

# Listar municipios -----------------------------------------------------
municipios <- c(
  3550308,   # Sao Paulo
  2507507,   # Joao Pessoa
  3106200,   # Belo Horizonte
  4314902,   # Porto Alegre
  1721000,   # Palmas
  5300108,   # Brasilia
  5208707    # Goiania
)

# Listar categorias de estabelecimentos
categorias <- c("deserto", "pantano")

# Calcular acesso -------------------------------------------------------
for (mun in municipios) {

  cat("Processando município:", mun, "\n")

  # Criar pasta 'acesso'
  dir_acesso <- file.path(dir_parcial, mun, "acesso")
  if (!dir.exists(dir_acesso)) dir.create(dir_acesso, recursive = TRUE)

  # Ler hexagonos para municipio ---
  caminho_hex <- file.path(dir_parcial, mun, "hex/hex_urbanizado.parquet")
  hex <- sfarrow::st_read_parquet(caminho_hex)

  # Loop nas categorias
  for (tipo in categorias) {

    cat(" -> Categoria:", tipo, "\n")

    # --------------------------------------------------------------- #
    caminho_ttm <- file.path(dir_parcial, mun, "rais/tempos", paste0("ttm_", tipo, ".rds"))
    # Ler tempos de viagem
    ttm <- readRDS(caminho_ttm)

    # --------------------------------------------------------------- #
    # Numero de estabelecimentos ate 15 minutos
    n_acesso_15 <- ttm %>%
      mutate(tempo_15 = ifelse(travel_time_p50 <= 15, 1, 0)) %>%
      group_by(from_id) %>%
      summarise(est_15 = sum(tempo_15, na.rm = TRUE), .groups = "drop")

    # Numero de estabelecimentos por 1000 habitantes
    n_acesso_15 <- hex %>%
      left_join(n_acesso_15, by = c("h3_address" = "from_id")) %>%
      mutate(est_pop_15 = est_15 / pop_bas_mor_tot_pes * 1000) %>%
      rename(from_id = h3_address) %>%
      dplyr::select(from_id, est_pop_15)

    n_acesso_15$est_pop_15[is.infinite(n_acesso_15$est_pop_15)] <- NA

    # Salvar resultado
    write_sf(
      n_acesso_15,
      file.path(dir_acesso, paste0("n_estab_15_", tipo, ".gpkg"))
    )

    # # Tempo minimo médio dos 3 estabelecimentos mais proximos
    #  tempo_minimo_medio_3 <- ttm %>%
    #   group_by(from_id) %>%
    #   summarise(
    #     tempo_min_medio_3 = mean(head(sort(travel_time_p50), 3), na.rm = TRUE),
    #     .groups = "drop"
    #   )
    #
    # # Juntar com hexagonos
    # mun_hex_med_3 <- hex %>%
    #   left_join(tempo_minimo_medio_3, by = c("h3_address" = "from_id")) #%>%
    #   #st_transform(31983)
    #
    # # Salvar resultado
    # write_sf(
    #   mun_hex_med_3,
    #   file.path(dir_acesso, "tempo_minmed_3_estab.gpkg")
    # )

    cat("Concluído município:", mun, "\n")
  }
}
```

## contagem_hex_na_00.R

```{r}
#| eval: false

# Bibliotecas ----
library(arrow)     # leitura de arquivos .parquet
library(sf)        # operações de geometria
library(ggplot2)   # Fazer mapas
library(dplyr)     # manipulação de dados
library(sfarrow)   # leitura de parquet com geometria
library(geobr)     # Ler geometrias de municipios
library(gridExtra)
library(grid)
library(ggnewscale)
library(cowplot)
library(ggspatial)
library(tidyr)

# Definir diretorio de trabalho -----------------------------------------
setwd("D:/CEM_acessoSAN/")

dir_inputs <- "1-inputs" # arquivos de input
dir_parcial <- "2-parcial" # arquivos intermediarios
dir_outputs <- "3-outputs" # arquivos finais

# Listar municipios -----------------------------------------------------
municipios <- c(
  3550308,   # Sao Paulo
  2507507,   # Joao Pessoa
  3106200,   # Belo Horizonte
  4314902,   # Porto Alegre
  1721000,   # Palmas
  5300108,   # Brasilia
  5208707    # Goiania
)

for (mun in municipios) {

  caminho_hex <- file.path(dir_parcial, mun, "hex/hex_urbanizado.parquet")
  hex <- sfarrow::st_read_parquet(caminho_hex)

  caminho_g0 <- file.path(dir_parcial, mun, "rais/tempos/ttm_g0.rds")
  acesso_g0 <- readRDS(caminho_g0) %>%
    mutate(tempo_15 = ifelse(travel_time_p50 <= 15, 1, 0)) %>%
    mutate(tempo_15 = replace_na(tempo_15, 0)) %>% # MUITO IMPORTA# Bibliotecas ----
library(arrow)     # leitura de arquivos .parquet
library(sf)        # operações de geometria
library(ggplot2)   # Fazer mapas
library(dplyr)     # manipulação de dados
library(sfarrow)   # leitura de parquet com geometria
library(geobr)     # Ler geometrias de municipios
library(gridExtra)
library(grid)
library(ggnewscale)
library(cowplot)
library(ggspatial)
library(tidyr)

# Definir diretorio de trabalho -----------------------------------------
setwd("D:/CEM_acessoSAN/")

dir_inputs <- "1-inputs" # arquivos de input
dir_parcial <- "2-parcial" # arquivos intermediarios
dir_outputs <- "3-outputs" # arquivos finais

# Listar municipios -----------------------------------------------------
municipios <- c(
  3550308,   # Sao Paulo
  2507507,   # Joao Pessoa
  3106200,   # Belo Horizonte
  4314902,   # Porto Alegre
  1721000,   # Palmas
  5300108,   # Brasilia
  5208707    # Goiania
)

for (mun in municipios) {

  caminho_hex <- file.path(dir_parcial, mun, "hex/hex_urbanizado.parquet")
  hex <- sfarrow::st_read_parquet(caminho_hex)

  caminho_g0 <- file.path(dir_parcial, mun, "rais/tempos/ttm_g0.rds")
  acesso_g0 <- readRDS(caminho_g0) %>%
    mutate(tempo_15 = ifelse(travel_time_p50 <= 15, 1, 0)) %>%
    mutate(tempo_15 = replace_na(tempo_15, 0)) %>% # MUITO IMPORTANTE: +de 60min era NA, agora 0!!!
    group_by(from_id) %>%
    summarise(n_g0_15min = sum(tempo_15, na.rm = TRUE), .groups = "drop")

  caminho_g4 <- file.path(dir_parcial, mun, "rais/tempos/ttm_g4.rds")
  acesso_g4 <- readRDS(caminho_g4) %>%
    mutate(tempo_15 = ifelse(travel_time_p50 <= 15, 1, 0)) %>%
    mutate(tempo_15 = replace_na(tempo_15, 0)) %>% # MUITO IMPORTANTE: +de 60min era NA, agora 0!!!
    group_by(from_id) %>%
    summarise(n_g4_15min = sum(tempo_15, na.rm = TRUE), .groups = "drop")

  hex_acesso <- hex %>%
    left_join(acesso_g0, by = c("h3_address" = "from_id")) %>%
    left_join(acesso_g4, by = c("h3_address" = "from_id")) %>%
    rename(from_id = h3_address) %>%
    mutate(
      rel_g0_g4 = case_when(
        is.na(n_g0_15min) ~ NA_real_,
        is.na(n_g4_15min) ~ NA_real_,
        n_g4_15min == 0 ~ NA_real_,
        TRUE ~ n_g0_15min / n_g4_15min
      ),

      indicador_so_g0 = n_g0_15min > 0 & n_g4_15min == 0,
      indicador_so_g4 = n_g4_15min == 0 & n_g4_15min > 0,
      indicador_sem_acesso_g0_g4 =
        (n_g0_15min == 0 | is.na(n_g0_15min)) &
        (n_g4_15min == 0 | is.na(n_g4_15min))
    ) %>%
    select(from_id, n_g0_15min, n_g4_15min, rel_g0_g4,
           indicador_so_g0, indicador_so_g4, indicador_sem_acesso_g0_g4)

  sf::st_write(hex_acesso, paste0(mun, "_relacao_g0_g4.gpkg"))

}
NTE: +de 60min era NA, agora 0!!!
    group_by(from_id) %>%
    summarise(n_g0_15min = sum(tempo_15, na.rm = TRUE), .groups = "drop")

  caminho_g4 <- file.path(dir_parcial, mun, "rais/tempos/ttm_g4.rds")
  acesso_g4 <- readRDS(caminho_g4) %>%
    mutate(tempo_15 = ifelse(travel_time_p50 <= 15, 1, 0)) %>%
    mutate(tempo_15 = replace_na(tempo_15, 0)) %>% # MUITO IMPORTANTE: +de 60min era NA, agora 0!!!
    group_by(from_id) %>%
    summarise(n_g4_15min = sum(tempo_15, na.rm = TRUE), .groups = "drop")

  hex_acesso <- hex %>%
    left_join(acesso_g0, by = c("h3_address" = "from_id")) %>%
    left_join(acesso_g4, by = c("h3_address" = "from_id")) %>%
    rename(from_id = h3_address) %>%
    mutate(
      rel_g0_g4 = case_when(
        is.na(n_g0_15min) ~ NA_real_,
        is.na(n_g4_15min) ~ NA_real_,
        n_g4_15min == 0 ~ NA_real_,
        TRUE ~ n_g0_15min / n_g4_15min
      ),

      indicador_so_g0 = n_g0_15min > 0 & n_g4_15min == 0,
      indicador_so_g4 = n_g4_15min == 0 & n_g4_15min > 0,
      indicador_sem_acesso_g0_g4 =
        (n_g0_15min == 0 | is.na(n_g0_15min)) &
        (n_g4_15min == 0 | is.na(n_g4_15min))
    ) %>%
    select(from_id, n_g0_15min, n_g4_15min, rel_g0_g4,
           indicador_so_g0, indicador_so_g4, indicador_sem_acesso_g0_g4)

  sf::st_write(hex_acesso, paste0(mun, "_relacao_g0_g4.gpkg"))

}
```

## Citation

::: {.callout-important}
When using this data, you must also cite the original data sources.
:::

To cite this work, please use the following format:

Soares, F., Penz, C., Vartanian, D., Fernandes, C. N., & Giannotti, M. A. (2025). *A reproducible pipeline for generating hexagonal grids of Brazilian municipalities* \[Computer software\]. Center for Metropolitan Studies of the University of São Paulo. <https://cem-usp.github.io/brazil-hexagonal-grid>

A BibTeX entry for LaTeX users is

```latex
@software{soares2025,
  title = {A reproducible pipeline for generating hexagonal grids of Brazilian municipalities},
  author = {{Flávio Soares} and {Clara Penz} and {Daniel Vartanian} and {Camila Nastari Fernandes} and {Mariana Abrantes Giannotti}},
  year = {2025},
  address = {São Paulo},
  institution = {Center for Metropolitan Studies of the University of São Paulo},
  langid = {en},
  url = {https://cem-usp.github.io/brazil-hexagonal-grid}
}
```

## License

::: {style="text-align: left;"}
[![License: GPLv3](https://img.shields.io/badge/license-GPLv3-bd0000.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC_BY--NC--SA_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
:::

::: {.callout-important}
The original data sources may be subject to their own licensing terms and conditions.
:::

The code in this report is licensed under the [GNU General Public License Version 3](https://www.gnu.org/licenses/gpl-3.0), while the report is available under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/).

``` text
Copyright (C) 2025 Center for Metropolitan Studies

The code in this report is free software: you can redistribute it and/or
modify it under the terms of the GNU General Public License as published by the
Free Software Foundation, either version 3 of the License, or (at your option)
any later version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program. If not, see <https://www.gnu.org/licenses/>.
```

## Acknowledgments

```{r, results='asis'}
#| eval: true
#| echo: false

blocks <- list(
  list(
    logo_link = "https://doi.org/10.17605/OSF.IO/ZE6WT",
    logo_src = "images/acessosan-logo.svg",
    logo_alt = "AcessoSAN Logo",
    logo_width = 140,
    text = 'This work is part of a research project by the Polytechnic School (<a href="https://www.poli.usp.br/">Poli</a>) of the University of São Paulo (<a href="https://usp.br/">USP</a>), in partnership with the Secretariat for Food and Nutrition Security (<a href="https://www.gov.br/mds/pt-br/orgaos/SESAN">SESAN</a>) of the Ministry of Social Development, Family, and the Fight Against Hunger (<a href="https://www.gov.br/mds/">MDS</a>), titled: <em>AcessoSAN: Mapping Food Access to Support Public Policies on Food and Nutrition Security and Hunger Reduction in Brazilian Cities</em>.'
  ),
  list(
    logo_link = "https://centrodametropole.fflch.usp.br",
    logo_src = "images/cem-icon.svg",
    logo_alt = "CEM Logo",
    logo_width = 190,
    text = 'This work was developed with support from the Center for Metropolitan Studies (<a href="https://centrodametropole.fflch.usp.br">CEM</a>) based at the School of Philosophy, Letters and Human Sciences (<a href="https://www.fflch.usp.br/">FFLCH</a>) of the University of São Paulo (<a href="https://usp.br">USP</a>) and at the Brazilian Center for Analysis and Planning (<a href="https://cebrap.org.br/">CEBRAP</a>).'
  ),
  list(
    logo_link = "https://fapesp.br/",
    logo_src = "images/fapesp-logo.svg",
    logo_alt = "FAPESP Logo",
    logo_width = 160,
    text = 'This study was financed, in part, by the São Paulo Research Foundation (<a href="https://fapesp.br/">FAPESP</a>), Brazil. Process Number <a href="https://bv.fapesp.br/en/bolsas/231507/geospatial-data-science-applied-to-food-policies/">2025/17879-2</a>.'
  )
)

blocks |>
  lapply(
    function(x) {
      div(
        style = paste0(
          "display: flex; ",
          "align-items: flex-start; ",
          "margin-bottom: 2em;"
        ),
        div(
          style = paste0(
            "flex: 0 0 30%; ",
            "display: flex; ",
            "justify-content: center; ",
            "margin: auto 0;"
          ),
          tags$a(
            href = x$logo_link,
            tags$img(
              src = x$logo_src,
              alt = x$logo_alt,
              style = paste0(
                "max-width: ", x$logo_width, "px; ",
                "width: 100%; ",
                "height: auto;"
              )
            )
          )
        ),
        div(
          style = paste0(
            "flex: 1; ",
            "padding-left: 1em;"
          ),
          HTML(x$text)
        )
      )
    }
  ) |>
  tagList() |>
  browsable()
```

## References {.unnumbered}

::: {#refs}
:::
